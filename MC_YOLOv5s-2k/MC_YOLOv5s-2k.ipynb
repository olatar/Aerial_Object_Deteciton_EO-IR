{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MC_YOLOv5s-2k.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"YMIxODDZQfrF"},"source":["# MC_YOLOv5s-2k\n","\n","This repository includes training of MC_YOLOv5s-2k object detection model with binary classes (object/no-object). Instead of a standard resolution of 640 and 720, 2144 is used in this notebook."]},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["# Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ie5uLDH4uzAp","executionInfo":{"status":"ok","timestamp":1607230134824,"user_tz":-60,"elapsed":2151,"user":{"displayName":"Ola_test Test","photoUrl":"","userId":"06496175701324816115"}},"outputId":"67db4db5-db80-4398-c3ee-39413a1931f5"},"source":["# clone YOLOv5 and reset to a specific git checkpoint that has been verified working\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","!git reset --hard 68211f72c99915a15855f7b99bf5d93f5631330f"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 24, done.\u001b[K\n","remote: Counting objects: 100% (24/24), done.\u001b[K\n","remote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 3189 (delta 11), reused 16 (delta 7), pack-reused 3165\u001b[K\n","Receiving objects: 100% (3189/3189), 6.46 MiB | 33.93 MiB/s, done.\n","Resolving deltas: 100% (2123/2123), done.\n","/content/yolov5\n","HEAD is now at 68211f7 FROM nvcr.io/nvidia/pytorch:20.10-py3 (#1553)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wbvMlHd_QwMG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607230143609,"user_tz":-60,"elapsed":9958,"user":{"displayName":"Ola_test Test","photoUrl":"","userId":"06496175701324816115"}},"outputId":"bf97d666-2066-4794-ae00-3b8298643221"},"source":["# install dependencies as necessary\n","!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","import torch\n","\n","from IPython.display import Image, clear_output  # to display images\n","from utils.google_utils import gdrive_download  # to download models/datasets\n","\n","# clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |█▏                              | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 21.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 20.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 11.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 9.3MB/s \n","\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Setup complete. Using torch 1.7.0+cu101 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SDIhrBF0sPaM"},"source":["# Download Correctly Formatted Custom Dataset \n","\n","This project use Roboflow.com to convert the data to the correct format."]},{"cell_type":"code","metadata":{"id":"Knxi2ncxWffW"},"source":["# Export code snippet and paste here\n","%cd /content\n","!curl -L \" \" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZ3DmmGQztJj"},"source":["# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n","%cat data.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwJx-2NHsYxT"},"source":["# Define Model Configuration and Architecture\n","\n","Change config YAML file for the model to be specified for the custom dataset."]},{"cell_type":"code","metadata":{"id":"dOPn9wjOAwwK"},"source":["# define number of classes based on YAML\n","import yaml\n","with open(\"data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Rvt5wilnDyX"},"source":["#this is the model configuration we will use for our tutorial \n","%cat /content/yolov5/models/yolov5s.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t14hhyqdmw6O"},"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uDxebz13RdRA"},"source":["%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VUOiNLtMP5aG"},"source":["# Train the YOLOv5 Detector\n","\n","Arguments:\n","- **img:** define input image size\n","- **batch:** determine batch size\n","- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n","- **data:** set the path to our yaml file\n","- **cfg:** specify our model configuration\n","- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n","- **name:** result names\n","- **nosave:** only save the final checkpoint\n","- **cache:** cache images for faster training"]},{"cell_type":"code","metadata":{"id":"1NcFxRcFdJ_O"},"source":["# time its performance\n","%%time\n","%cd /content/yolov5/\n","!python train.py --img 2144 --batch 8 --epochs 500 --data '../data.yaml' --cfg ./models/custom_yolov5s.yaml --weights /content/gdrive/MyDrive/0thesis/Hi-res/MC_v5small_2144/trial3_2144imsize/intermed2_weights/1940_last.pt --name yolov5s_results  --cache"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kJVs_4zEeVbF"},"source":["# Evaluate Custom YOLOv5 Detector Performance"]},{"cell_type":"code","metadata":{"id":"bOy5KI2ncnWd"},"source":["# Start tensorboard\n","# logs save in the folder \"runs\"\n","%load_ext tensorboard\n","%tensorboard --logdir runs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uPq9mVgiBql"},"source":["# Export Trained Weights for Future Inference\n","\n","Export the trained weights to Google Drive"]},{"cell_type":"code","metadata":{"id":"YH4CTzDRh00g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607230244830,"user_tz":-60,"elapsed":19359,"user":{"displayName":"Ola_test Test","photoUrl":"","userId":"06496175701324816115"}},"outputId":"38cae9e3-eeeb-4d74-9f58-0a871479c763"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1x_wg3VeiXMW"},"source":["%cp -r /content/yolov5/runs/train/yolov5s_results/weights/last.pt /content/gdrive/MyDrive/0thesis/Hi-res/MC_v5small_2144/trial3_2144imsize/intermed2_weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRhZmqhMqQtQ"},"source":["# Evaluate on test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JI6qEn5fZTBk","executionInfo":{"status":"ok","timestamp":1606899893648,"user_tz":-60,"elapsed":1287,"user":{"displayName":"Ola Tranum","photoUrl":"https://lh5.googleusercontent.com/-IRdqnmPZ8x0/AAAAAAAAAAI/AAAAAAAAADc/AZKV6LdqcWM/s64/photo.jpg","userId":"16412047261917522426"}},"outputId":"d51bd351-5d23-4586-dbc7-026dbe9be3fb"},"source":["%%writefile /content/data.yaml\n","train: /content/train/images\n","val: /content/valid/images\n","test: /content/test/images\n","\n","nc: 5\n","names: ['Boat', 'Buoy', 'Pallet', 'Pole', 'Vest']"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting /content/data.yaml\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hQiVaf66Z5Of"},"source":["%cd /content/yolov5/\n","!python test.py --weights /content/yolov5/runs/train/yolov5s_results5/weights/last.pt --img-size 640 --conf-thres 0.001 --data /content/data.yaml --task 'test' --verbose"],"execution_count":null,"outputs":[]}]}
