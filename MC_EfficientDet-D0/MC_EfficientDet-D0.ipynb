{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MC_EffDet_v5.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyNSIj9KvrQGHRurvGaJuq5J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"g6QqNN44L0j_"},"source":["# EfficientDet-D0 MC\n","\n","This repository includes training of EfficientDet-D0 object detection model with multiple classes (pallet, boat, pole, vest and boat). This model requires significant time of training."]},{"cell_type":"markdown","metadata":{"id":"l7EOtpvlLeS0"},"source":["# Install TensorFlow2 Object Detection Dependencies"]},{"cell_type":"code","metadata":{"id":"ypWGYdPlLRUN"},"source":["import os\n","import pathlib\n","\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QPmVBSlLTzM"},"source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHfsJ5nWLWh9"},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import os\n","import random\n","import io\n","import imageio\n","import glob\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display, Javascript\n","from IPython.display import Image as IPyImage\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import colab_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wh_HPMOqWH9z"},"source":["#run model builder test\n","!python /content/models/research/object_detection/builders/model_builder_tf2_test.py\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VA7Zbo3RLt3W"},"source":["def load_image_into_numpy_array(path):\n","  \"\"\"Load an image from file into a numpy array.\n","\n","  Puts image into numpy array to feed into tensorflow graph.\n","  Note that by convention we put it into a numpy array with shape\n","  (height, width, channels), where channels=3 for RGB.\n","\n","  Args:\n","    path: a file path.\n","\n","  Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","  \"\"\"\n","  img_data = tf.io.gfile.GFile(path, 'rb').read()\n","  image = Image.open(BytesIO(img_data))\n","  (im_width, im_height) = image.size\n","  return np.array(image.getdata()).reshape(\n","      (im_height, im_width, 3)).astype(np.uint8)\n","\n","def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index,\n","                    figsize=(12, 16),\n","                    image_name=None):\n","  \"\"\"Wrapper function to visualize detections.\n","\n","  Args:\n","    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n","    boxes: a numpy array of shape [N, 4]\n","    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n","      and match the keys in the label map.\n","    scores: a numpy array of shape [N] or None.  If scores=None, then\n","      this function assumes that the boxes to be plotted are groundtruth\n","      boxes and plot all boxes as black with no classes or scores.\n","    category_index: a dict containing category dictionaries (each holding\n","      category index `id` and category name `name`) keyed by category indices.\n","    figsize: size for the figure.\n","    image_name: a name for the image file.\n","  \"\"\"\n","  image_np_with_annotations = image_np.copy()\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_annotations,\n","      boxes,\n","      classes,\n","      scores,\n","      category_index,\n","      use_normalized_coordinates=True,\n","      min_score_thresh=0.8)\n","  if image_name:\n","    plt.imsave(image_name, image_np_with_annotations)\n","  else:\n","    plt.imshow(image_np_with_annotations)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IPbU4I7aL9Fl"},"source":["# Download Correctly Formatted Custom Dataset \n","\n","This project use Roboflow.com to convert the data to the correct format."]},{"cell_type":"code","metadata":{"id":"NFdE42MVfPcG"},"source":["#Downloading data from Roboflow\n","#UPDATE THIS LINK - get our data from Roboflow\n","%cd /content\n","!curl -L \"https://app.roboflow.com/ds/hnzKg4iYtU?key=we4TWscrwv\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUd2wtfrqedy"},"source":["# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n","test_record_fname = '/content/valid/Objects.tfrecord'\n","train_record_fname = '/content/train/Objects.tfrecord'\n","label_map_pbtxt_fname = '/content/train/Objects_label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2MAcgJ53STW"},"source":["# Define Model Configuration and Architecture\n","\n"]},{"cell_type":"code","metadata":{"id":"gN0EUEa3e5Un"},"source":["##change chosen model to deploy different models available in the TF2 object detection zoo\n","MODELS_CONFIG = {\n","    'efficientdet-d0': {\n","        'model_name': 'efficientdet_d0_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d1': {\n","        'model_name': 'efficientdet_d1_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","    'efficientdet-d2': {\n","        'model_name': 'efficientdet_d2_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n","        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    },\n","        'efficientdet-d3': {\n","        'model_name': 'efficientdet_d3_coco17_tpu-32',\n","        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n","        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n","        'batch_size': 16\n","    }\n","}\n","\n","chosen_model = 'efficientdet-d0'\n","\n","num_steps = 100000 #The more steps, the longer the training.\n","num_eval_steps = 500 #Perform evaluation after so many steps\n","\n","model_name = MODELS_CONFIG[chosen_model]['model_name']\n","pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n","base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n","batch_size = MODELS_CONFIG[chosen_model]['batch_size']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ug2PQIsCErNO"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"kG4TmJUVrYQ7"},"source":["#download pretrained weights\n","%mkdir /content/models/research/deploy/\n","%cd /content/models/research/deploy/\n","import tarfile\n","download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n","\n","!wget {download_tar}\n","tar = tarfile.open(pretrained_checkpoint)\n","tar.extractall()\n","tar.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-nqYZtdtsgG"},"source":["#download base training configuration file\n","%cd /content/models/research/deploy\n","download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n","!wget {download_config}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_ki9jOqxn7V"},"source":["#prepare\n","pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n","fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n","\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eA5ht3_yukT"},"source":["#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n","\n","import re\n","\n","%cd /content/models/research/deploy\n","print('writing custom configuration file')\n","\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open('pipeline_file.config', 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    \n","    #fine-tune checkpoint type\n","    s = re.sub(\n","        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n","        \n","    f.write(s)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMlaN3rs3zLe"},"source":["pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n","model_dir = '/content/training/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XxPj_QV43qD5"},"source":["# Train Object Detector\n","\n","* pipeline_file: defined above in writing custom training configuration\n","* model_dir: the location tensorboard logs and saved model checkpoints will save to\n","* num_train_steps: how long to train for\n","* num_eval_steps: perform eval on validation set after this many steps\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"tQTfZChVzzpZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608686765842,"user_tz":-60,"elapsed":918,"user":{"displayName":"Ola Tranum","photoUrl":"https://lh5.googleusercontent.com/-IRdqnmPZ8x0/AAAAAAAAAAI/AAAAAAAAADc/AZKV6LdqcWM/s64/photo.jpg","userId":"16412047261917522426"}},"outputId":"a8f1dd28-38aa-4f03-dfe9-c7de87972706"},"source":["!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps={num_steps} \\\n","    --sample_1_of_n_eval_examples=1 \\\n","    --num_eval_steps={num_eval_steps}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["python3: can't open file '/content/models/research/object_detection/model_main_tf2.py': [Errno 2] No such file or directory\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SArv74iqNdWD"},"source":["# Evaluate on test data\n","\n","Must change data formatting in the beginning of the notebook to include test data in the validation directory."]},{"cell_type":"code","metadata":{"id":"9KNv1N_hUibE"},"source":["#run model evaluation to obtain performance metrics\n","!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_file} \\\n","    --model_dir={model_dir} \\\n","    --checkpoint_dir={model_dir} \\\n","#Not yet implemented for EfficientDet"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"us9VJNU6NY8U"},"source":["# Evaluate Custom YOLOv5 Detector Performance"]},{"cell_type":"code","metadata":{"id":"TI9iCCxoNlAL"},"source":["%load_ext tensorboard\n","%tensorboard --logdir '/content/training/train'"],"execution_count":null,"outputs":[]}]}